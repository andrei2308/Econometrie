"Shelf.Life..days.", "Quantity.Sold..liters.kg.",
"Price.per.Unit..sold.", "Approx..Total.Revenue.INR.",
"Quantity.in.Stock..liters.kg.", "Minimum.Stock.Threshold..liters.kg.",
"Reorder.Quantity..liters.kg.")
data <- farm_data[, numerical_columns]
# Eliminarea valorilor lipsa
data <- na.omit(data)
# Separarea in variabile predictori si tinta
X <- as.matrix(data[, !colnames(data) %in% "Approx..Total.Revenue.INR."])
y <- as.vector(data$Approx..Total.Revenue.INR.)
# Standardizarea datelor
X_scaled <- scale(X)
# Impartirea datelor in seturi de antrenament si test
set.seed(42)
train_index <- sample(1:nrow(X_scaled), size = 0.8 * nrow(X_scaled))
X_train <- X_scaled[train_index, ]
X_test <- X_scaled[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
# Lasso Regression
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_coefs <- coef(lasso_model, s = "lambda.min")
print("Lasso Coefficients:")
print(lasso_coefs)
# Ridge Regression
ridge_model <- cv.glmnet(X_train, y_train, alpha = 0, standardize = FALSE)
ridge_coefs <- coef(ridge_model, s = "lambda.min")
print("Ridge Coefficients:")
print(ridge_coefs)
# Elastic Net Regression
elastic_net_model <- cv.glmnet(X_train, y_train, alpha = 0.5, standardize = FALSE)
elastic_net_coefs <- coef(elastic_net_model, s = "lambda.min")
print("Elastic Net Coefficients:")
print(elastic_net_coefs)
# Evaluarea modelelor
lasso_pred <- predict(lasso_model, X_test, s = "lambda.min")
ridge_pred <- predict(ridge_model, X_test, s = "lambda.min")
elastic_net_pred <- predict(elastic_net_model, X_test, s = "lambda.min")
lasso_rmse <- sqrt(mean((lasso_pred - y_test)^2))
ridge_rmse <- sqrt(mean((ridge_pred - y_test)^2))
elastic_net_rmse <- sqrt(mean((elastic_net_pred - y_test)^2))
cat("Lasso RMSE:", lasso_rmse, "\n")
cat("Ridge RMSE:", ridge_rmse, "\n")
cat("Elastic Net RMSE:", elastic_net_rmse, "\n")
# Alegerea Lasso si eliminarea variabilelor nesemnificative
significant_vars <- rownames(as.matrix(lasso_coefs))[as.matrix(lasso_coefs) != 0 & rownames(as.matrix(lasso_coefs)) != "(Intercept)"]
cat("Variabile semnificative selectate de Lasso:\n")
print(significant_vars)
# Crearea unui nou set de date cu variabilele semnificative
data_significant <- data[, significant_vars]
X_significant <- as.matrix(data_significant)
# Reantrenarea modelului Lasso doar pe variabilele semnificative
set.seed(42)
train_index <- sample(1:nrow(X_significant), size = 0.8 * nrow(X_significant))
X_train <- X_significant[train_index, ]
X_test <- X_significant[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
lasso_model_refined <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_pred_refined <- predict(lasso_model_refined, X_test, s = "lambda.min")
lasso_rmse_refined <- sqrt(mean((lasso_pred_refined - y_test)^2))
cat("Lasso RMSE cu variabilele semnificative:", lasso_rmse_refined, "\n")
#observam ca modelul s-a imbunatatit in urma eliminarii variabilelor nesemnificative
# Model de regresie multipla folosind variabilele semnificative
final_data <- data.frame(data_significant, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multipla:\n")
print(summary_model)
#eliminam variabilele nesemnificative statistic din modelul de regresie multipla
selected_vars <- c("Price.per.Unit", "Total.Value", "Quantity.Sold..liters.kg.", "Price.per.Unit..sold.", "Quantity.in.Stock..liters.kg.")
data_refined <- data[, selected_vars]
# Model de regresie multipla cu variabile semnificative
final_data <- data.frame(data_refined, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multipla cu variabile semnificative:\n")
print(summary_model)
#=================================================IPOTEZA 1========================================
#Verificam liniaritatea functionalei
# Testarea liniarității funcționale
cat("\nTestarea liniarității funcționale pentru", farm_size, "farms:\n")
# Grafic reziduuri vs. valori ajustate
plot(fitted(model), resid(model),
main = paste("Residuals vs Fitted (", farm_size, " Farms)", sep = ""),
xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red")
# Test RESET pentru specificația modelului
reset_test <- resettest(model, power = 2:3, type = "fitted")
cat("Rezultatele testului RESET:\n")
print(reset_test)
# Dacă testul RESET indică o specificație incorectă (p-value < 0.05):
if (reset_test$p.value < 0.05) {
cat("\nFuncția specificată nu este liniară. Aplicăm transformări asupra datelor.\n")
# Transformări logaritmice
#=================================================IPOTEZA 2========================================
# Testarea variabilității pozitive în X
cat("\nTestarea variabilității în X pentru", farm_size, "farms:\n")
# Calculăm varianța pentru fiecare predictor
variances <- apply(X, 2, var)
cat("Varianțele predictorilor:\n")
print(variances)
# Verificăm dacă există predictori cu varianță aproape de 0
low_variance <- names(variances[variances < 1e-6])
if (length(low_variance) > 0) {
cat("Predictori cu variabilitate scăzută:\n")
print(low_variance)
} else {
cat("Toți predictorii au o variabilitate pozitivă semnificativă.\n")
}
# Verificare grafică a distribuției variabilelor predictori
par(mfrow = c(2, 2))  # Afișăm mai multe grafice pe un rând
for (colname in colnames(X)) {
hist(X[, colname], main = paste("Distribuția predictorului", colname),
xlab = colname, col = "blue", border = "white")
}
#=================================================IPOTEZA 3========================================
# Testarea ipotezei 3: Erorile au media 0
cat("\nTestarea ipotezei 3: Erorile au media 0 pentru", farm_size, "farms:\n")
# Calculăm media reziduurilor
residuals_mean <- mean(resid(model))
cat("Media reziduurilor:", residuals_mean, "\n")
# Verificăm dacă media este aproape de 0
if (abs(residuals_mean) < 1e-6) {
cat("Media reziduurilor este foarte aproape de 0. Ipoteza este satisfăcută.\n")
} else {
cat("Media reziduurilor este semnificativ diferită de 0. Ipoteza este încălcată.\n")
}
# Histogramă a reziduurilor
hist(resid(model), breaks = 30, main = paste("Histogramă a reziduurilor (", farm_size, " Farms)", sep = ""),
xlab = "Reziduuri", col = "blue", border = "white")
abline(v = 0, col = "red", lwd = 2)
#=================================================IPOTEZA 4========================================
# Testarea ipotezei 4: Homoscedasticitatea erorilor
}
process_farm_data(small_farms,"Mici")
# Crearea subseturilor
small_farms <- subset(dataset, Farm.Size == "Small")
medium_farms <- subset(dataset, Farm.Size == "Medium")
large_farms <- subset(dataset, Farm.Size == "Large")
process_farm_data <- function(farm_data,farm_size)
{
# Selectarea variabilelor numerice
numerical_columns <- c("Total.Land.Area..acres.", "Number.of.Cows", "Product.ID",
"Quantity..liters.kg.", "Price.per.Unit", "Total.Value",
"Shelf.Life..days.", "Quantity.Sold..liters.kg.",
"Price.per.Unit..sold.", "Approx..Total.Revenue.INR.",
"Quantity.in.Stock..liters.kg.", "Minimum.Stock.Threshold..liters.kg.",
"Reorder.Quantity..liters.kg.")
data <- farm_data[, numerical_columns]
# Eliminarea valorilor lipsa
data <- na.omit(data)
# Separarea in variabile predictori si tinta
X <- as.matrix(data[, !colnames(data) %in% "Approx..Total.Revenue.INR."])
y <- as.vector(data$Approx..Total.Revenue.INR.)
# Standardizarea datelor
X_scaled <- scale(X)
# Impartirea datelor in seturi de antrenament si test
set.seed(42)
train_index <- sample(1:nrow(X_scaled), size = 0.8 * nrow(X_scaled))
X_train <- X_scaled[train_index, ]
X_test <- X_scaled[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
# Lasso Regression
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_coefs <- coef(lasso_model, s = "lambda.min")
print("Lasso Coefficients:")
print(lasso_coefs)
# Ridge Regression
ridge_model <- cv.glmnet(X_train, y_train, alpha = 0, standardize = FALSE)
ridge_coefs <- coef(ridge_model, s = "lambda.min")
print("Ridge Coefficients:")
print(ridge_coefs)
# Elastic Net Regression
elastic_net_model <- cv.glmnet(X_train, y_train, alpha = 0.5, standardize = FALSE)
elastic_net_coefs <- coef(elastic_net_model, s = "lambda.min")
print("Elastic Net Coefficients:")
print(elastic_net_coefs)
# Evaluarea modelelor
lasso_pred <- predict(lasso_model, X_test, s = "lambda.min")
ridge_pred <- predict(ridge_model, X_test, s = "lambda.min")
elastic_net_pred <- predict(elastic_net_model, X_test, s = "lambda.min")
lasso_rmse <- sqrt(mean((lasso_pred - y_test)^2))
ridge_rmse <- sqrt(mean((ridge_pred - y_test)^2))
elastic_net_rmse <- sqrt(mean((elastic_net_pred - y_test)^2))
cat("Lasso RMSE:", lasso_rmse, "\n")
cat("Ridge RMSE:", ridge_rmse, "\n")
cat("Elastic Net RMSE:", elastic_net_rmse, "\n")
# Alegerea Lasso si eliminarea variabilelor nesemnificative
significant_vars <- rownames(as.matrix(lasso_coefs))[as.matrix(lasso_coefs) != 0 & rownames(as.matrix(lasso_coefs)) != "(Intercept)"]
cat("Variabile semnificative selectate de Lasso:\n")
print(significant_vars)
# Crearea unui nou set de date cu variabilele semnificative
data_significant <- data[, significant_vars]
X_significant <- as.matrix(data_significant)
# Reantrenarea modelului Lasso doar pe variabilele semnificative
set.seed(42)
train_index <- sample(1:nrow(X_significant), size = 0.8 * nrow(X_significant))
X_train <- X_significant[train_index, ]
X_test <- X_significant[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
lasso_model_refined <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_pred_refined <- predict(lasso_model_refined, X_test, s = "lambda.min")
lasso_rmse_refined <- sqrt(mean((lasso_pred_refined - y_test)^2))
cat("Lasso RMSE cu variabilele semnificative:", lasso_rmse_refined, "\n")
#observam ca modelul s-a imbunatatit in urma eliminarii variabilelor nesemnificative
# Model de regresie multipla folosind variabilele semnificative
final_data <- data.frame(data_significant, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multipla:\n")
print(summary_model)
#eliminam variabilele nesemnificative statistic din modelul de regresie multipla
selected_vars <- c("Price.per.Unit", "Total.Value", "Quantity.Sold..liters.kg.", "Price.per.Unit..sold.", "Quantity.in.Stock..liters.kg.")
data_refined <- data[, selected_vars]
# Model de regresie multipla cu variabile semnificative
final_data <- data.frame(data_refined, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multipla cu variabile semnificative:\n")
print(summary_model)
#=================================================IPOTEZA 1========================================
#Verificam liniaritatea functionalei
# Testarea liniarității funcționale
cat("\nTestarea liniarității funcționale pentru", farm_size, "farms:\n")
# Grafic reziduuri vs. valori ajustate
plot(fitted(model), resid(model),
main = paste("Residuals vs Fitted (", farm_size, " Farms)", sep = ""),
xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red")
# Test RESET pentru specificația modelului
reset_test <- resettest(model, power = 2:3, type = "fitted")
cat("Rezultatele testului RESET:\n")
print(reset_test)
# Dacă testul RESET indică o specificație incorectă (p-value < 0.05):
#=================================================IPOTEZA 2========================================
# Testarea variabilității pozitive în X
cat("\nTestarea variabilității în X pentru", farm_size, "farms:\n")
# Calculăm varianța pentru fiecare predictor
variances <- apply(X, 2, var)
cat("Varianțele predictorilor:\n")
print(variances)
# Verificăm dacă există predictori cu varianță aproape de 0
low_variance <- names(variances[variances < 1e-6])
if (length(low_variance) > 0) {
cat("Predictori cu variabilitate scăzută:\n")
print(low_variance)
} else {
cat("Toți predictorii au o variabilitate pozitivă semnificativă.\n")
}
# Verificare grafică a distribuției variabilelor predictori
par(mfrow = c(2, 2))  # Afișăm mai multe grafice pe un rând
for (colname in colnames(X)) {
hist(X[, colname], main = paste("Distribuția predictorului", colname),
xlab = colname, col = "blue", border = "white")
}
#=================================================IPOTEZA 3========================================
# Testarea ipotezei 3: Erorile au media 0
cat("\nTestarea ipotezei 3: Erorile au media 0 pentru", farm_size, "farms:\n")
# Calculăm media reziduurilor
residuals_mean <- mean(resid(model))
cat("Media reziduurilor:", residuals_mean, "\n")
# Verificăm dacă media este aproape de 0
if (abs(residuals_mean) < 1e-6) {
cat("Media reziduurilor este foarte aproape de 0. Ipoteza este satisfăcută.\n")
} else {
cat("Media reziduurilor este semnificativ diferită de 0. Ipoteza este încălcată.\n")
}
# Histogramă a reziduurilor
hist(resid(model), breaks = 30, main = paste("Histogramă a reziduurilor (", farm_size, " Farms)", sep = ""),
xlab = "Reziduuri", col = "blue", border = "white")
abline(v = 0, col = "red", lwd = 2)
#=================================================IPOTEZA 4========================================
# Testarea ipotezei 4: Homoscedasticitatea erorilor
}
process_farm_data(small_farms,"Mici")
# Crearea subseturilor
small_farms <- subset(dataset, Farm.Size == "Small")
medium_farms <- subset(dataset, Farm.Size == "Medium")
large_farms <- subset(dataset, Farm.Size == "Large")
process_farm_data <- function(farm_data, farm_size) {
library(glmnet)
library(car)
library(lmtest)
# Selectarea variabilelor numerice
numerical_columns <- c("Total.Land.Area..acres.", "Number.of.Cows", "Product.ID",
"Quantity..liters.kg.", "Price.per.Unit", "Total.Value",
"Shelf.Life..days.", "Quantity.Sold..liters.kg.",
"Price.per.Unit..sold.", "Approx..Total.Revenue.INR.",
"Quantity.in.Stock..liters.kg.", "Minimum.Stock.Threshold..liters.kg.",
"Reorder.Quantity..liters.kg.")
data <- farm_data[, numerical_columns]
data <- na.omit(data)  # Eliminarea valorilor lipsă
# Separarea în variabile predictori și țintă
X <- as.matrix(data[, !colnames(data) %in% "Approx..Total.Revenue.INR."])
y <- as.vector(data$Approx..Total.Revenue.INR.)
# Standardizarea datelor
X_scaled <- scale(X)
# Împărțirea datelor în seturi de antrenament și test
set.seed(42)
train_index <- sample(1:nrow(X_scaled), size = 0.8 * nrow(X_scaled))
X_train <- X_scaled[train_index, ]
X_test <- X_scaled[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
# Lasso Regression
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_coefs <- coef(lasso_model, s = "lambda.min")
significant_vars <- rownames(as.matrix(lasso_coefs))[as.matrix(lasso_coefs) != 0 & rownames(as.matrix(lasso_coefs)) != "(Intercept)"]
# Crearea unui set de date cu variabile semnificative
data_significant <- data[, significant_vars, drop = FALSE]
X_significant <- as.matrix(data_significant)
# Reantrenarea modelului de regresie multiplă
final_data <- data.frame(data_significant, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multiplă pentru", farm_size, "farms:\n")
print(summary_model)
#=================================================IPOTEZA 1========================================
# Testarea liniarității funcționale
cat("\nTestarea liniarității funcționale pentru", farm_size, "farms:\n")
plot(fitted(model), resid(model),
main = paste("Residuals vs Fitted (", farm_size, " Farms)", sep = ""),
xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red")
# Test RESET pentru specificația modelului
reset_test <- resettest(model, power = 2:3, type = "fitted")
cat("\nRezultatele testului RESET:\n")
print(reset_test)
#=================================================IPOTEZA 2========================================
# Testarea variabilității pozitive în X
cat("\nTestarea variabilității în X pentru", farm_size, "farms:\n")
variances <- apply(X, 2, var)
cat("Varianțele predictorilor:\n")
print(variances)
#=================================================IPOTEZA 3========================================
# Testarea ipotezei 3: Erorile au media 0
residuals_mean <- mean(resid(model))
cat("\nMedia reziduurilor:", residuals_mean, "\n")
# Histogramă a reziduurilor
hist(resid(model), breaks = 30,
main = paste("Histogramă a reziduurilor (", farm_size, " Farms)", sep = ""),
xlab = "Reziduuri", col = "blue", border = "white")
#=================================================IPOTEZA 4========================================
# Testarea ipotezei 4: Homoscedasticitatea erorilor
cat("\nTestarea homoscedasticității pentru", farm_size, "farms:\n")
bp_test <- bptest(model)
cat("\nRezultatele testului Breusch-Pagan:\n")
print(bp_test)
white_test <- bptest(model, ~ fitted(model) + I(fitted(model)^2))
cat("\nRezultatele testului White:\n")
print(white_test)
}
process_farm_data(small_farms,"Mici")
process_farm_data(medium_farms,"Medii")
process_farm_data(large_farms,"Mari")
process_farm_data(small_farms, "Small")
process_farm_data(medium_farms, "Medium")
process_farm_data(large_farms, "Large")
library(lmtest)
library(glmnet)
library(caret)
library(stats)
library(MASS)
library(sandwich)
library(tseries)
# Incarcarea datelor
dataset <- read.csv("dairy_dataset.csv", header = TRUE, sep = ",")
# Crearea subseturilor
small_farms <- subset(dataset, Farm.Size == "Small")
medium_farms <- subset(dataset, Farm.Size == "Medium")
large_farms <- subset(dataset, Farm.Size == "Large")
process_farm_data <- function(farm_data,farm_size)
{
# Selectarea variabilelor numerice
numerical_columns <- c("Total.Land.Area..acres.", "Number.of.Cows", "Product.ID",
"Quantity..liters.kg.", "Price.per.Unit", "Total.Value",
"Shelf.Life..days.", "Quantity.Sold..liters.kg.",
"Price.per.Unit..sold.", "Approx..Total.Revenue.INR.",
"Quantity.in.Stock..liters.kg.", "Minimum.Stock.Threshold..liters.kg.",
"Reorder.Quantity..liters.kg.")
data <- farm_data[, numerical_columns]
# Eliminarea valorilor lipsa
data <- na.omit(data)
# Separarea in variabile predictori si tinta
X <- as.matrix(data[, !colnames(data) %in% "Approx..Total.Revenue.INR."])
y <- as.vector(data$Approx..Total.Revenue.INR.)
# Standardizarea datelor
X_scaled <- scale(X)
# Impartirea datelor in seturi de antrenament si test
set.seed(42)
train_index <- sample(1:nrow(X_scaled), size = 0.8 * nrow(X_scaled))
X_train <- X_scaled[train_index, ]
X_test <- X_scaled[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
# Lasso Regression
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_coefs <- coef(lasso_model, s = "lambda.min")
print("Lasso Coefficients:")
print(lasso_coefs)
# Ridge Regression
ridge_model <- cv.glmnet(X_train, y_train, alpha = 0, standardize = FALSE)
ridge_coefs <- coef(ridge_model, s = "lambda.min")
print("Ridge Coefficients:")
print(ridge_coefs)
# Elastic Net Regression
elastic_net_model <- cv.glmnet(X_train, y_train, alpha = 0.5, standardize = FALSE)
elastic_net_coefs <- coef(elastic_net_model, s = "lambda.min")
print("Elastic Net Coefficients:")
print(elastic_net_coefs)
# Evaluarea modelelor
lasso_pred <- predict(lasso_model, X_test, s = "lambda.min")
ridge_pred <- predict(ridge_model, X_test, s = "lambda.min")
elastic_net_pred <- predict(elastic_net_model, X_test, s = "lambda.min")
lasso_rmse <- sqrt(mean((lasso_pred - y_test)^2))
ridge_rmse <- sqrt(mean((ridge_pred - y_test)^2))
elastic_net_rmse <- sqrt(mean((elastic_net_pred - y_test)^2))
cat("Lasso RMSE:", lasso_rmse, "\n")
cat("Ridge RMSE:", ridge_rmse, "\n")
cat("Elastic Net RMSE:", elastic_net_rmse, "\n")
# Alegerea Lasso si eliminarea variabilelor nesemnificative
significant_vars <- rownames(as.matrix(lasso_coefs))[as.matrix(lasso_coefs) != 0 & rownames(as.matrix(lasso_coefs)) != "(Intercept)"]
cat("Variabile semnificative selectate de Lasso:\n")
print(significant_vars)
# Crearea unui nou set de date cu variabilele semnificative
data_significant <- data[, significant_vars]
X_significant <- as.matrix(data_significant)
# Reantrenarea modelului Lasso doar pe variabilele semnificative
set.seed(42)
train_index <- sample(1:nrow(X_significant), size = 0.8 * nrow(X_significant))
X_train <- X_significant[train_index, ]
X_test <- X_significant[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]
lasso_model_refined <- cv.glmnet(X_train, y_train, alpha = 1, standardize = FALSE)
lasso_pred_refined <- predict(lasso_model_refined, X_test, s = "lambda.min")
lasso_rmse_refined <- sqrt(mean((lasso_pred_refined - y_test)^2))
cat("Lasso RMSE cu variabilele semnificative:", lasso_rmse_refined, "\n")
#observam ca modelul s-a imbunatatit in urma eliminarii variabilelor nesemnificative
# Model de regresie multipla folosind variabilele semnificative
final_data <- data.frame(data_significant, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multipla:\n")
print(summary_model)
#eliminam variabilele nesemnificative statistic din modelul de regresie multipla
selected_vars <- c("Price.per.Unit", "Total.Value", "Quantity.Sold..liters.kg.", "Price.per.Unit..sold.", "Quantity.in.Stock..liters.kg.")
data_refined <- data[, selected_vars]
# Model de regresie multipla cu variabile semnificative
final_data <- data.frame(data_refined, Revenue = y)
model <- lm(Revenue ~ ., data = final_data)
summary_model <- summary(model)
cat("\nRezumatul modelului de regresie multipla cu variabile semnificative:\n")
print(summary_model)
#=================================================IPOTEZA 1========================================
#Verificam liniaritatea functionalei
# Testarea liniarității funcționale
cat("\nTestarea liniarității funcționale pentru", farm_size, "farms:\n")
# Grafic reziduuri vs. valori ajustate
plot(fitted(model), resid(model),
main = paste("Residuals vs Fitted (", farm_size, " Farms)", sep = ""),
xlab = "Fitted values", ylab = "Residuals")
abline(h = 0, col = "red")
# Test RESET pentru specificația modelului
reset_test <- resettest(model, power = 2:3, type = "fitted")
cat("Rezultatele testului RESET:\n")
print(reset_test)
# Dacă testul RESET indică o specificație incorectă (p-value < 0.05):
#=================================================IPOTEZA 2========================================
# Testarea variabilității pozitive în X
cat("\nTestarea variabilității în X pentru", farm_size, "farms:\n")
# Calculăm varianța pentru fiecare predictor
variances <- apply(X, 2, var)
cat("Varianțele predictorilor:\n")
print(variances)
# Verificăm dacă există predictori cu varianță aproape de 0
low_variance <- names(variances[variances < 1e-6])
if (length(low_variance) > 0) {
cat("Predictori cu variabilitate scăzută:\n")
print(low_variance)
} else {
cat("Toți predictorii au o variabilitate pozitivă semnificativă.\n")
}
# Verificare grafică a distribuției variabilelor predictori
par(mfrow = c(2, 2))  # Afișăm mai multe grafice pe un rând
for (colname in colnames(X)) {
hist(X[, colname], main = paste("Distribuția predictorului", colname),
xlab = colname, col = "blue", border = "white")
}
#=================================================IPOTEZA 3========================================
# Testarea ipotezei 3: Erorile au media 0
cat("\nTestarea ipotezei 3: Erorile au media 0 pentru", farm_size, "farms:\n")
# Calculăm media reziduurilor
residuals_mean <- mean(resid(model))
cat("Media reziduurilor:", residuals_mean, "\n")
# Verificăm dacă media este aproape de 0
if (abs(residuals_mean) < 1e-6) {
cat("Media reziduurilor este foarte aproape de 0. Ipoteza este satisfăcută.\n")
} else {
cat("Media reziduurilor este semnificativ diferită de 0. Ipoteza este încălcată.\n")
}
# Histogramă a reziduurilor
hist(resid(model), breaks = 30, main = paste("Histogramă a reziduurilor (", farm_size, " Farms)", sep = ""),
xlab = "Reziduuri", col = "blue", border = "white")
abline(v = 0, col = "red", lwd = 2)
#=================================================IPOTEZA 4========================================
# Testarea ipotezei 4: Homoscedasticitatea erorilor
}
process_farm_data(small_farms,"Mici")
